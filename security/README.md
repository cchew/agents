# Security

## Data security

1. Clear and transparent data collection, storage and usage statement
1. Focus on 'how model produces output'
1. Filter before and after LLM (see 'Content filtering')
1. Implement AI guardrails
1. Consider privacy-focused LLM, e.g. SLM on browser
1. Allow user to opt-out of data collection
1. Consider data anonymisation, differential privacy, secure multi-party computation, secure model serving, federated learning.

## Content filtering

1. [PAIG (includes security, safety and observability)](https://github.com/privacera/paig)
1. [Guardrails.ai](https://github.com/guardrails-ai/guardrails)
1. [Nightfall Firewall for AI](https://help.nightfall.ai/firewall-for-ai/nightfall-use-cases/gen_ai_content_filtering)
1. [Gecholog.ai custom content filters](https://www.gecholog.ai/blog/Securing-Data-Confidentiality-Deploying-Custom-Content-Filters)
1. [Build custom using Groq API](https://deveshsurve.medium.com/beginners-guide-to-llms-build-a-content-moderation-filter-and-learn-advanced-prompting-with-free-87f3bad7c0af)

## Resource

1. https://www.protecto.ai/blog/how-to-preserve-data-privacy-in-llms
1. TODO [On protecting the data privacy of Large Language Models (LLMs) and LLM agents: A literature review](https://www.sciencedirect.com/science/article/pii/S2667295225000042)
1. TODO [AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap](https://hdsr.mitpress.mit.edu/pub/aelql9qy/release/2)